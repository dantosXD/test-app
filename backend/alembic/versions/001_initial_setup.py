"""initial_setup

Revision ID: 001
Revises: 
Create Date: 2025-05-29 19:00:00.000000 

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '001'
down_revision: str | None = None
branch_labels: str | None = None
depends_on: str | None = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('users',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('email', sa.String(), nullable=False),
        sa.Column('password_hash', sa.String(), nullable=False),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_users_email'), 'users', ['email'], unique=True)
    op.create_index(op.f('ix_users_id'), 'users', ['id'], unique=False)

    op.create_table('bases',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('owner_id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.ForeignKeyConstraint(['owner_id'], ['users.id'], ),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_bases_id'), 'bases', ['id'], unique=False)
    op.create_index(op.f('ix_bases_owner_id'), 'bases', ['owner_id'], unique=False)

    op.create_table('tables',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('base_id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.ForeignKeyConstraint(['base_id'], ['bases.id'], ),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_tables_id'), 'tables', ['id'], unique=False)
    op.create_index(op.f('ix_tables_base_id'), 'tables', ['base_id'], unique=False)

    op.create_table('fields',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('table_id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.Column('type', sa.String(), nullable=False),
        sa.Column('options', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.ForeignKeyConstraint(['table_id'], ['tables.id'], ),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_fields_id'), 'fields', ['id'], unique=False)
    op.create_index(op.f('ix_fields_table_id'), 'fields', ['table_id'], unique=False)

    op.create_table('records',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('table_id', sa.Integer(), nullable=False),
        sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
        sa.Column('updated_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True), # onupdate=func.now() is handled by SQLAlchemy, not directly in DDL for server_default here for creation
        sa.ForeignKeyConstraint(['table_id'], ['tables.id'], ),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_records_id'), 'records', ['id'], unique=False)
    op.create_index(op.f('ix_records_table_id'), 'records', ['table_id'], unique=False)

    op.create_table('record_values',
        sa.Column('id', sa.Integer(), autoincrement=True, nullable=False),
        sa.Column('record_id', sa.Integer(), nullable=False),
        sa.Column('field_id', sa.Integer(), nullable=False),
        sa.Column('value_text', sa.Text(), nullable=True),
        sa.Column('value_number', sa.Float(), nullable=True),
        sa.Column('value_boolean', sa.Boolean(), nullable=True),
        sa.Column('value_datetime', sa.DateTime(timezone=True), nullable=True),
        sa.Column('value_json', postgresql.JSONB(astext_type=sa.Text()), nullable=True),
        sa.ForeignKeyConstraint(['field_id'], ['fields.id'], ),
        sa.ForeignKeyConstraint(['record_id'], ['records.id'], ),
        sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_record_values_id'), 'record_values', ['id'], unique=False)
    op.create_index(op.f('ix_record_values_record_id'), 'record_values', ['record_id'], unique=False)
    op.create_index(op.f('ix_record_values_field_id'), 'record_values', ['field_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index(op.f('ix_record_values_field_id'), table_name='record_values')
    op.drop_index(op.f('ix_record_values_record_id'), table_name='record_values')
    op.drop_index(op.f('ix_record_values_id'), table_name='record_values')
    op.drop_table('record_values')

    op.drop_index(op.f('ix_records_table_id'), table_name='records')
    op.drop_index(op.f('ix_records_id'), table_name='records')
    op.drop_table('records')

    op.drop_index(op.f('ix_fields_table_id'), table_name='fields')
    op.drop_index(op.f('ix_fields_id'), table_name='fields')
    op.drop_table('fields')

    op.drop_index(op.f('ix_tables_base_id'), table_name='tables')
    op.drop_index(op.f('ix_tables_id'), table_name='tables')
    op.drop_table('tables')

    op.drop_index(op.f('ix_bases_owner_id'), table_name='bases')
    op.drop_index(op.f('ix_bases_id'), table_name='bases')
    op.drop_table('bases')

    op.drop_index(op.f('ix_users_id'), table_name='users')
    op.drop_index(op.f('ix_users_email'), table_name='users')
    op.drop_table('users')
    # ### end Alembic commands ###
